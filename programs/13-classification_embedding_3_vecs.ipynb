{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Language Detection\n",
    "\n",
    "Authors: Pierre Nugues and Marcus Klang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reimplementation of Google's _Compact language detector_ (CLD3) from a high-level description. Read the description here: https://github.com/google/cld3\n",
    "\n",
    "The model has three different embeddings as first layer\n",
    "\n",
    "Note: The types are wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your classifier will read a short text, typically a few words or a sentence, and output the probability for all languages observed during training. The text will have a variable length and will be encoded as a Unicode string.\n",
    "\n",
    "As dataset to train your models, you will use [Tatoeba](https://tatoeba.org/sv/), a collaborative, open, and free collection of sentences and translations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will break down the task into four steps:\n",
    "    \n",
    "  1. Data processing, converting the data into a machine-learnable representation\n",
    "  2. Try and evaluate a simple model, logistic regression. This will be your baseline.\n",
    "  3. Try and evaluate a deeper model inspired by Google's compact language detector, CLD3.\n",
    "  4. CLD3 includes an embedding vectorization. This last part is left as an optional exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model: CLD3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLD3 has three major characteristics:\n",
    "\n",
    "   * It uses **$n$-grams** and splits an input text like _banana_ into three feature vectors that include:\n",
    "       + Each unique character, unigrams ($n=1$)\n",
    "       + Each unique pair of characters obtained from a sliding window of size 2, bigrams ($n=2$)\n",
    "       + Each unique triple of characters obtained from a sliding window of size 3, trigrams ($n=3$)\n",
    "       + These feature sets map to a set of indices (integer value).\n",
    "   \n",
    "   * It **hashes each symbol** i.e. it encrypts the $n$-gram into a fixed range integer.\n",
    "       + This way of mapping features to indices is called feature hashing or the *hashing trick*\n",
    "       + It reduces the number of symbols.\n",
    "       + Constant memory requirements, depends on the hash function -- commonly only a few constants.\n",
    "       + It is an approximate method as collisions can and will occur. Adjusting the size of the feature space i.e. the number of features to hash to, the collision probability can be reduced.\n",
    "   \n",
    "   * For each value of $n$, 1, 2, and 3, CLD3 computes the relative frequencies of the $n$-grams and **use them as weights**. See the figure below.\n",
    "       + The model can map the input indices to embedding vectors (this part is optional)\n",
    "       + It then computes the **weighted average** of the embeddings (this part is optional)\n",
    "       + The model learns the embeddings during training (also optional)\n",
    "       \n",
    "The figure below shows the final architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model overview](https://raw.githubusercontent.com/google/cld3/master/model.png)\n",
    "Image source: https://github.com/google/cld3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Tatoeba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your instructors have downsampled Tatoeba to reduce training times and guarantee that all the students have the same datasets.\n",
    "* Link to datasets: https://github.com/pnugues/edan96/tree/main/classification%20lab\n",
    "* Link to preprocessing notebook: https://github.com/pnugues/edan96/blob/main/programs/5-tatoeba_eda_select.ipynb\n",
    "\n",
    "You are only required to process the small dataset. The larger one may take take and be difficult to process on small computers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import hashlib\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc4d8739610>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(4321)\n",
    "torch.manual_seed(4321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME_TRAIN = 'train.tsv'\n",
    "FILENAME_VAL = 'val.tsv'\n",
    "FILENAME_TEST = 'test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_DATASET_PATH = 'small_dataset'\n",
    "LARGE_DATASET_PATH = 'large_dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "You have here the most significant settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGE_DATASET = True # Use the small or large dataset\n",
    "REL_FREQ = True # How we represent the n-grams in the input vector: with their relative frequency or with a 1 (NOT USED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_LAYER = False  # Neural network with one hidden layer or logistic regression\n",
    "EPOCHS = 6 # Number of epochs\n",
    "BATCH_SIZE = 128 # How many examples we will use for an update in the gradient descent\n",
    "EMBEDDING_DIM = 64\n",
    "EMBEDDING_DIM_UNI = 32\n",
    "EMBEDDING_DIM_BI = 64\n",
    "EMBEDDING_DIM_TRI = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LARGE_DATASET:\n",
    "    dataset_path = LARGE_DATASET_PATH\n",
    "else:\n",
    "    dataset_path = SMALL_DATASET_PATH\n",
    "    \n",
    "FILE_TRAIN = dataset_path + '/' + FILENAME_TRAIN\n",
    "FILE_VAL = dataset_path + '/' + FILENAME_VAL\n",
    "FILE_TEST = dataset_path + '/' + FILENAME_TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a generator to read the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_reader(file: str):\n",
    "    with open(file, encoding='utf8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            row = line.strip()\n",
    "            yield tuple(row.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_generator = file_reader(FILE_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we count the sentences per language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_freqs = Counter(map(lambda x: x[1], line_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rus', 12314),\n",
       " ('mkd', 12149),\n",
       " ('lfn', 12132),\n",
       " ('srp', 12127),\n",
       " ('lit', 12126),\n",
       " ('lat', 12115),\n",
       " ('bul', 12111),\n",
       " ('ukr', 12093),\n",
       " ('ell', 12084),\n",
       " ('vie', 12079),\n",
       " ('nld', 12074),\n",
       " ('hau', 12073),\n",
       " ('kab', 12066),\n",
       " ('ron', 12065),\n",
       " ('deu', 12064)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_freqs.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ara', 'ber', 'bul', 'ces', 'cmn', 'dan', 'deu', 'ell', 'eng', 'epo']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs = sorted(list(set(lang_freqs.keys())))\n",
    "langs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will create an index of the languages of your dataset: Assign a number to each language. You will call it `idx2lang` and its type will be a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2lang = {idx:lang for idx, lang in enumerate(langs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'ara',\n",
       " 1: 'ber',\n",
       " 2: 'bul',\n",
       " 3: 'ces',\n",
       " 4: 'cmn',\n",
       " 5: 'dan',\n",
       " 6: 'deu',\n",
       " 7: 'ell',\n",
       " 8: 'eng',\n",
       " 9: 'epo',\n",
       " 10: 'fin',\n",
       " 11: 'fra',\n",
       " 12: 'hau',\n",
       " 13: 'heb',\n",
       " 14: 'hun',\n",
       " 15: 'ina',\n",
       " 16: 'ita',\n",
       " 17: 'jpn',\n",
       " 18: 'kab',\n",
       " 19: 'lat',\n",
       " 20: 'lfn',\n",
       " 21: 'lit',\n",
       " 22: 'mar',\n",
       " 23: 'mkd',\n",
       " 24: 'nld',\n",
       " 25: 'pes',\n",
       " 26: 'pol',\n",
       " 27: 'por',\n",
       " 28: 'ron',\n",
       " 29: 'rus',\n",
       " 30: 'spa',\n",
       " 31: 'srp',\n",
       " 32: 'swc',\n",
       " 33: 'swe',\n",
       " 34: 'tlh',\n",
       " 35: 'tok',\n",
       " 36: 'tur',\n",
       " 37: 'ukr',\n",
       " 38: 'vie'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the reverted `lang2idx` index to convert languages to indices. It is also a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang2idx = {lang:idx for idx, lang in idx2lang.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ara': 0,\n",
       " 'ber': 1,\n",
       " 'bul': 2,\n",
       " 'ces': 3,\n",
       " 'cmn': 4,\n",
       " 'dan': 5,\n",
       " 'deu': 6,\n",
       " 'ell': 7,\n",
       " 'eng': 8,\n",
       " 'epo': 9,\n",
       " 'fin': 10,\n",
       " 'fra': 11,\n",
       " 'hau': 12,\n",
       " 'heb': 13,\n",
       " 'hun': 14,\n",
       " 'ina': 15,\n",
       " 'ita': 16,\n",
       " 'jpn': 17,\n",
       " 'kab': 18,\n",
       " 'lat': 19,\n",
       " 'lfn': 20,\n",
       " 'lit': 21,\n",
       " 'mar': 22,\n",
       " 'mkd': 23,\n",
       " 'nld': 24,\n",
       " 'pes': 25,\n",
       " 'pol': 26,\n",
       " 'por': 27,\n",
       " 'ron': 28,\n",
       " 'rus': 29,\n",
       " 'spa': 30,\n",
       " 'srp': 31,\n",
       " 'swc': 32,\n",
       " 'swe': 33,\n",
       " 'tlh': 34,\n",
       " 'tok': 35,\n",
       " 'tur': 36,\n",
       " 'ukr': 37,\n",
       " 'vie': 38}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing — convert the sentences into feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the context of this program, a feature is a string of 1 to 3 characters. \n",
    "In natural language processing, they are called $n$-grams as they can have a varying size and are created from a sliding window.\n",
    "\n",
    "Common sizes of $n$ have names unigrams ($n$=1), bigrams ($n$=2), and trigrams ($n$=3))\n",
    "\n",
    "To serve as input, we have to convert these $n$-grams to numbers. There are two common ways to encode features into indices:\n",
    " * Mapping each symbol to an index\n",
    "    + Exact and precise\n",
    "    + Can have high memory requirements with vast feature spaces as each known feature must be stored and be assigned a unique index.\n",
    "    + Slow, you need to precompute your feature space, convert the incoming data to an index and retain the mapping in memory at all times.\n",
    " * Hashing trick: hash the feature into a index\n",
    "    + Supports an arbitrary number of features with the caveat of collisions.\n",
    "    + Constant memory requirements\n",
    "    + Fast, any feature even an unknown one can be converted into a feature index\n",
    "    + However, if the feature space is too small, features will have many collisions. You have then to choose a good hash function and a feature space that is big enough\n",
    "    \n",
    "We will use the [hashing trick](https://en.wikipedia.org/wiki/Feature_hashing). In Python, `hash` is a function that converts any supported object into a number (hash code) but it is not reproducible across the sessions - it changes each time the interpreter is started.\n",
    "We have therefore provided a new function `reproducible_hash` that hashes a string but in a reproducible way.\n",
    "\n",
    "The number returned by `reproducible_hash` is big and needs to be converted into a limited space. This can be done with the use of the remainder of an integer division, the [modulo](https://en.wikipedia.org/wiki/Modulo_operation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting $n$-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an $n$-gram function that returns the $n$-grams of a string. The $n$ value will be passed as an argument. You will optionally set the string in lower case (`lc` argument)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(sentence: str, n: int =1, lc: bool =True) -> List[str]:\n",
    "    ngram_l = []\n",
    "    if lc:\n",
    "        sentence = sentence.lower()\n",
    "    for i in range(len(sentence) - n + 1):\n",
    "        ngram_l += [sentence[i:i+n]]\n",
    "    return ngram_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_ngrams(sentence: str, max_ngram: int =3, lc: bool =True) -> List[List[str]]:\n",
    "    all_ngram_list = []\n",
    "    for i in range(1, max_ngram + 1):\n",
    "        all_ngram_list += [ngrams(sentence, n=i, lc=lc)]\n",
    "    return all_ngram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['b', 'a', 'n', 'a', 'n', 'a'],\n",
       " ['ba', 'an', 'na', 'an', 'na'],\n",
       " ['ban', 'ana', 'nan', 'ana']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ngrams('banana')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limiting the $n$-grams numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the modulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LARGE_DATASET:\n",
    "    MAX_CHARS = 2053\n",
    "    MAX_BIGRAMS = 4099\n",
    "    MAX_TRIGRAMS = 4099  #8192\n",
    "else:\n",
    "    MAX_CHARS = 521\n",
    "    MAX_BIGRAMS = 1031\n",
    "    MAX_TRIGRAMS = 1031 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10251"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_FEATURES = MAX_CHARS + MAX_BIGRAMS + MAX_TRIGRAMS\n",
    "NUM_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproducible_hash(string: str) -> int:\n",
    "    \"\"\"\n",
    "    reproducible hash on any string\n",
    "    \n",
    "    Arguments:\n",
    "       string: python string object\n",
    "    \n",
    "    Returns:\n",
    "       signed int64\n",
    "    \"\"\"\n",
    "    \n",
    "    # We are using MD5 for speed not security.\n",
    "    h = hashlib.md5(string.encode(\"utf-8\"), usedforsecurity=False)\n",
    "    return int.from_bytes(h.digest()[0:8], 'big', signed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[95, 3321, 824, 3321]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[reproducible_hash(x) % MAX_TRIGRAMS for x in all_ngrams('banana')[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXES = [MAX_CHARS, MAX_BIGRAMS, MAX_TRIGRAMS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `ngrams2hashvals` function that creates a list of hash codes from a list of $n$-grams. As arguments, you will have the list of $n$-grams as well as the list of dividers (`MAXES`). See the example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams2hashvals(ngrams: List[List[str]], modulos: List[int]) -> List[List[int]]:\n",
    "    hash_values = []\n",
    "    for ngram_l, modulo in zip(ngrams, modulos):\n",
    "        hash_values += [[reproducible_hash(x) % modulo for x in ngram_l]]\n",
    "    return hash_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[98, 1917, 1195, 1917, 1195, 1917],\n",
       " [426, 3906, 2726, 3906, 2726],\n",
       " [95, 3321, 824, 3321]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashvals_banana = ngrams2hashvals(all_ngrams('banana'), MAXES)\n",
    "hashvals_banana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash codes relative frequencies\n",
    "CLD3 associates the $n$-gram hash codes with their relative frequencies in the text. See the example in Google CLD3 page.\n",
    "\n",
    "Create a `rel_freqs` function that computes the frequencies from lists of hash codes. The input will be a list of three lists of hash codes, for the unigrams, bigrams, and trigrams. The output will be a list of a three dictionaries, where the keys will be the $n$-gram hash codes and the values, the relative frequency. See example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_freqs(lst: list) -> Dict[int, float]:\n",
    "    return {ngram: lst.count(ngram)/len(lst) \n",
    "           for ngram in set(lst)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{98: 0.16666666666666666, 1195: 0.3333333333333333, 1917: 0.5},\n",
       " {426: 0.2, 3906: 0.4, 2726: 0.4},\n",
       " {824: 0.25, 3321: 0.5, 95: 0.25}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash2freqs_banana = [rel_freqs(x) for x in hashvals_banana]\n",
    "hash2freqs_banana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating $X$ and $\\mathbf{y}$ tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function to read the files and return the language and the sentence. We create the $X$ and $\\mathbf{y}$ tensors from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sent_lang(file: str):\n",
    "    with open(file, encoding='utf8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            row = line.strip()\n",
    "            lang_tuple = tuple(row.split('\\t'))\n",
    "            yield lang_tuple[2], lang_tuple[1]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a $X$ and $\\mathbf{y}$ tensors. Note that $X$ is a matrix and $\\mathbf{y}$, a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting the Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams_bags(hash2freqs: List[Dict[int, float]]) -> Tuple[List[List[int]], List[List[float]]]:\n",
    "    indices = []\n",
    "    freqs = []\n",
    "    for i, hash2freq in enumerate(hash2freqs):\n",
    "        indices += [torch.LongTensor(list(hash2freq.keys()))]\n",
    "        freqs += [torch.FloatTensor(list(hash2freq.values()))]\n",
    "    return indices, freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{98: 0.16666666666666666, 1195: 0.3333333333333333, 1917: 0.5},\n",
       " {426: 0.2, 3906: 0.4, 2726: 0.4},\n",
       " {824: 0.25, 3321: 0.5, 95: 0.25}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash2freqs_banana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([  98, 1195, 1917]),\n",
       "  tensor([ 426, 3906, 2726]),\n",
       "  tensor([ 824, 3321,   95])],\n",
       " [tensor([0.1667, 0.3333, 0.5000]),\n",
       "  tensor([0.2000, 0.4000, 0.4000]),\n",
       "  tensor([0.2500, 0.5000, 0.2500])])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_idx_banana, freqs  = ngrams_bags(hash2freqs_banana)\n",
    "hash_idx_banana, freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Xy_symb(file: str, lang2idx: Dict[int, int], MAXES: List[int]) -> Tuple[List, List, torch.LongTensor]:\n",
    "    y_symb = []\n",
    "    line_cnt = 0\n",
    "    for sentence, lang in read_sent_lang(file):\n",
    "        line_cnt += 1\n",
    "    X_idx_l = []\n",
    "    X_freqs_l = []\n",
    "    for sentence, lang in tqdm(read_sent_lang(file)):\n",
    "        hashvals = ngrams2hashvals(all_ngrams(sentence), MAXES)\n",
    "        hash2freqs_l = list(map(rel_freqs, hashvals))\n",
    "        bags = ngrams_bags(hash2freqs_l)\n",
    "        X_idx_l += [bags[0]]\n",
    "        X_freqs_l += [bags[1]]\n",
    "        y_symb += [lang]\n",
    "    y = torch.LongTensor(list(map(lang2idx.get, y_symb)))\n",
    "    return X_idx_l, X_freqs_l, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "468422it [02:05, 3742.46it/s]\n",
      "58552it [00:16, 3620.26it/s]\n",
      "58554it [00:16, 3651.83it/s]\n"
     ]
    }
   ],
   "source": [
    "X_idx_train, X_freqs_train, y_train = create_Xy_symb(FILE_TRAIN, lang2idx, MAXES)\n",
    "X_idx_val, X_freqs_val, y_val = create_Xy_symb(FILE_VAL, lang2idx, MAXES)\n",
    "X_idx_test, X_freqs_test, y_test = create_Xy_symb(FILE_TEST, lang2idx, MAXES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([1028, 1030, 1164, 1935, 1040,  406, 1943,  159,  931, 1446, 1354,  589,\n",
       "          1365, 1634, 1250, 1509, 1770, 1260, 1263,  370,  627, 1782,  505, 1278]),\n",
       "  tensor([1027, 1796,  271, 1553, 2962, 3478, 2966, 1177,  153, 1309,  671, 3488,\n",
       "           291, 3619, 2347,  688, 2224, 3379, 2869,  953, 2628, 3782, 1734, 4053,\n",
       "          3158, 3676, 1759, 2401, 2020, 1125, 1256, 3817,  234, 1007,  880, 3441,\n",
       "          1393, 2802, 2929, 1141, 2421, 4087,  893,  638]),\n",
       "  tensor([ 509, 3716, 1925,  519, 3983,  528, 3477, 1558,   23, 1560, 3739,  162,\n",
       "          2852, 3750,  424,  427, 1836, 2992,  304, 1334, 3319, 2366, 2498, 1475,\n",
       "           325, 3703, 2761,  714, 3019,  970, 3538, 1108, 2262,  346, 3419, 3292,\n",
       "          2526, 3304,  114,  757, 3959,  637, 1790])],\n",
       " [tensor([0.0222, 0.0444, 0.0222, 0.0222, 0.0667, 0.0222, 0.0222, 0.0222, 0.0444,\n",
       "          0.1556, 0.0222, 0.0222, 0.0222, 0.0667, 0.0222, 0.0444, 0.1111, 0.0222,\n",
       "          0.0222, 0.0444, 0.0222, 0.0444, 0.0444, 0.0444]),\n",
       "  tensor([0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227,\n",
       "          0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227,\n",
       "          0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227,\n",
       "          0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227,\n",
       "          0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227]),\n",
       "  tensor([0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233,\n",
       "          0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233,\n",
       "          0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233,\n",
       "          0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233,\n",
       "          0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233])])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_idx_train[0], X_freqs_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a vector (1D tensor) from two lists to make a bag with the offsets\n",
    "def bag_generator_one(X_idx_l: List[torch.LongTensor],  \n",
    "                       X_freqs_l: List[torch.FloatTensor]) -> Tuple[torch.LongTensor, torch.LongTensor, torch.FloatTensor]:\n",
    "    \"\"\"\n",
    "    We process here one type of n-gram, where n = 1, or 2, or 3.\n",
    "    We concatenate all the items of a bag so that they fit on one line\n",
    "    We track the items with their offsets from the start. This is just the cumulative sum of their length\n",
    "    Input: \n",
    "    1/ a list of tensors containing the n-gram indices\n",
    "    2/ a list of tensors containing the n-gram freqs.\n",
    "    We concatenate 1/ and 2/: Two 1D tensors. \n",
    "    We compute the offsets\n",
    "    \"\"\"\n",
    "    # Easy part\n",
    "    X_idx = torch.cat(X_idx_l, dim=-1)\n",
    "    X_freqs = torch.cat(X_freqs_l, dim=-1)\n",
    "\n",
    "    # More difficult: We must compute the offsets\n",
    "    bag_lengths = [X_idx_l[i].size()[0] for i in range(len(X_idx_l))]\n",
    "    X_offsets = torch.LongTensor([sum(bag_lengths[:i]) for i in range(len(bag_lengths))])\n",
    "     \n",
    "    return X_idx, X_offsets, X_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_generator(X_idx_l: list, X_freqs_l: list):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    1/ X_idx_l lists of [unigrams, bigrams, trigrams] indices\n",
    "    2/ X_freqs_l lists of [unigrams, bigrams, trigrams] frequencies\n",
    "    We transpose them as lists of \n",
    "    [[unigrams indices],  \n",
    "    [bigrams indices], \n",
    "    [trigrams indices]]\n",
    "    and\n",
    "    [[unigrams frequencies],\n",
    "    [bigrams frequencies],\n",
    "    [trigrams frequencies]]\n",
    "    \"\"\"\n",
    "    # We transpose the lists\n",
    "    X_idx_t_l = list(zip(*X_idx_l))\n",
    "    X_freq_t_l = list(zip(*X_freqs_l))\n",
    "\n",
    "    bags_uni_idx = X_idx_t_l[0]\n",
    "    bags_uni_freqs = X_freq_t_l[0]\n",
    "    bags_uni_idx, bags_uni_offsets, bags_uni_freqs = bag_generator_one(bags_uni_idx, bags_uni_freqs)\n",
    "\n",
    "    bags_bi_idx = X_idx_t_l[1]\n",
    "    bags_bi_freqs = X_freq_t_l[1]\n",
    "    bags_bi_idx, bags_bi_offsets, bags_bi_freqs = bag_generator_one(bags_bi_idx, bags_bi_freqs)\n",
    "\n",
    "    bags_tri_idx = X_idx_t_l[2]\n",
    "    bags_tri_freqs = X_freq_t_l[2]\n",
    "    bags_tri_idx, bags_tri_offsets, bags_tri_freqs = bag_generator_one(bags_tri_idx, bags_tri_freqs)\n",
    "    \n",
    "    return (bags_uni_idx, bags_uni_offsets, bags_uni_freqs), (bags_bi_idx, bags_bi_offsets, bags_bi_freqs), (bags_tri_idx, bags_tri_offsets, bags_tri_freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([1028, 1030, 1164, 1935, 1040,  406, 1943,  159,  931, 1446, 1354,  589,\n",
       "          1365, 1634, 1250, 1509, 1770, 1260, 1263,  370,  627, 1782,  505, 1278,\n",
       "           832,   98,  676, 1446,  584, 1418, 1195,   76, 1645, 1917,   46, 1810,\n",
       "           406, 1079, 1304,   90,  989]),\n",
       "  tensor([ 0, 24]),\n",
       "  tensor([0.0222, 0.0444, 0.0222, 0.0222, 0.0667, 0.0222, 0.0222, 0.0222, 0.0444,\n",
       "          0.1556, 0.0222, 0.0222, 0.0222, 0.0667, 0.0222, 0.0444, 0.1111, 0.0222,\n",
       "          0.0222, 0.0444, 0.0222, 0.0444, 0.0444, 0.0444, 0.0263, 0.0263, 0.0526,\n",
       "          0.1316, 0.0789, 0.0263, 0.0526, 0.0526, 0.0789, 0.0789, 0.0263, 0.0263,\n",
       "          0.0263, 0.0263, 0.0263, 0.0789, 0.1842])),\n",
       " (tensor([1027, 1796,  271, 1553, 2962, 3478, 2966, 1177,  153, 1309,  671, 3488,\n",
       "           291, 3619, 2347,  688, 2224, 3379, 2869,  953, 2628, 3782, 1734, 4053,\n",
       "          3158, 3676, 1759, 2401, 2020, 1125, 1256, 3817,  234, 1007,  880, 3441,\n",
       "          1393, 2802, 2929, 1141, 2421, 4087,  893,  638, 1281, 2181, 1542,  777,\n",
       "           910,  145, 2716, 2465, 1315, 2726, 2088,  812, 2097, 3633,  309, 2487,\n",
       "           577, 1476, 2629, 2118, 1486, 3160,  473, 2140, 2271, 2663, 3176,  743,\n",
       "          4075,  622,  760, 2172,  510]),\n",
       "  tensor([ 0, 44]),\n",
       "  tensor([0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227,\n",
       "          0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227,\n",
       "          0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227,\n",
       "          0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227,\n",
       "          0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0227, 0.0270,\n",
       "          0.0541, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
       "          0.0270, 0.0270, 0.0270, 0.0270, 0.0541, 0.0270, 0.0541, 0.0270, 0.0270,\n",
       "          0.0541, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270, 0.0270,\n",
       "          0.0270, 0.0270, 0.0270, 0.0270, 0.0270])),\n",
       " (tensor([ 509, 3716, 1925,  519, 3983,  528, 3477, 1558,   23, 1560, 3739,  162,\n",
       "          2852, 3750,  424,  427, 1836, 2992,  304, 1334, 3319, 2366, 2498, 1475,\n",
       "           325, 3703, 2761,  714, 3019,  970, 3538, 1108, 2262,  346, 3419, 3292,\n",
       "          2526, 3304,  114,  757, 3959,  637, 1790, 3842,  903, 1162,  275,   21,\n",
       "          3095, 3739, 1439, 2724, 2297, 3754, 3115, 3632, 3520, 3009, 3777, 3780,\n",
       "           325, 1734, 1354, 4051, 3415, 1502, 2783, 3935, 1122,  866, 3684, 2662,\n",
       "          1127, 1515, 1260, 1773, 3061, 1401]),\n",
       "  tensor([ 0, 43]),\n",
       "  tensor([0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233,\n",
       "          0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233,\n",
       "          0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233,\n",
       "          0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233,\n",
       "          0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0233, 0.0278, 0.0278,\n",
       "          0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278,\n",
       "          0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0556,\n",
       "          0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278,\n",
       "          0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0278])))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigr, bigr, trigr = bag_generator(X_idx_train[:2], X_freqs_train[:2])\n",
    "unigr, bigr, trigr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEmbeddingLR(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        self.embed_uni = nn.EmbeddingBag(MAX_CHARS, EMBEDDING_DIM_UNI, mode='sum')\n",
    "        self.embed_bi = nn.EmbeddingBag(MAX_BIGRAMS, EMBEDDING_DIM_BI, mode='sum')\n",
    "        self.embed_tri = nn.EmbeddingBag(MAX_TRIGRAMS, EMBEDDING_DIM_TRI, mode='sum')\n",
    "\n",
    "        self.fc_uni = nn.Linear(EMBEDDING_DIM_UNI, len(langs))\n",
    "        self.fc_bi = nn.Linear(EMBEDDING_DIM_BI, len(langs))\n",
    "        self.fc_tri = nn.Linear(EMBEDDING_DIM_TRI, len(langs))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        bags_uni, bags_bi, bags_tri = X\n",
    "        X_uni = self.embed_uni(bags_uni[0], bags_uni[1], bags_uni[2]) # unigr_idx, unigr_offsets, unigr_freqs\n",
    "        X_bi = self.embed_bi(bags_bi[0], bags_bi[1], bags_bi[2])      # bigr_idx, bigr_offsets, bigr_freqs\n",
    "        X_tri = self.embed_tri(bags_tri[0], bags_tri[1], bags_tri[2]) # trigr_idx, trigr_offsets, trigr_freqs\n",
    "        X = self.fc_uni(X_uni) + self.fc_bi(X_bi) + self.fc_tri(X_tri)\n",
    "        return X\n",
    "\n",
    "    def evaluate(self, X, y, loss_fn):\n",
    "        with torch.no_grad():\n",
    "            Y_pred = self.forward(X)\n",
    "            loss = loss_fn(Y_pred, y)\n",
    "            y_pred = torch.argmax(Y_pred, dim=-1)\n",
    "            acc = torch.sum(y == y_pred)/y.size()[0]\n",
    "            return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEmbeddingNN(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        self.embed_uni = nn.EmbeddingBag(MAX_CHARS, EMBEDDING_DIM_UNI, mode='sum')\n",
    "        self.embed_bi = nn.EmbeddingBag(MAX_BIGRAMS, EMBEDDING_DIM_BI, mode='sum')\n",
    "        self.embed_tri = nn.EmbeddingBag(MAX_TRIGRAMS, EMBEDDING_DIM_TRI, mode='sum')\n",
    "\n",
    "        self.fc1_uni = nn.Linear(EMBEDDING_DIM_UNI, EMBEDDING_DIM)\n",
    "        self.fc1_bi = nn.Linear(EMBEDDING_DIM_BI, EMBEDDING_DIM)\n",
    "        self.fc1_tri = nn.Linear(EMBEDDING_DIM_TRI, EMBEDDING_DIM)\n",
    "        self.fc2 = nn.Linear(EMBEDDING_DIM, len(langs))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        bags_uni, bags_bi, bags_tri = X\n",
    "        X_uni = self.embed_uni(bags_uni[0], bags_uni[1], bags_uni[2]) # unigr_idx, unigr_offsets, unigr_freqs\n",
    "        X_bi = self.embed_bi(bags_bi[0], bags_bi[1], bags_bi[2])      # bigr_idx, bigr_offsets, bigr_freqs\n",
    "        X_tri = self.embed_tri(bags_tri[0], bags_tri[1], bags_tri[2]) # trigr_idx, trigr_offsets, trigr_freqs\n",
    "        X = self.fc1_uni(X_uni) + self.fc1_bi(X_bi) + self.fc1_tri(X_tri)\n",
    "        X = torch.relu(X)\n",
    "        X = self.fc2(X)\n",
    "        return X\n",
    "    \n",
    "    def evaluate(self, X, y, loss_fn):\n",
    "        with torch.no_grad():\n",
    "            Y_pred = self.forward(X)\n",
    "            loss = loss_fn(Y_pred, y)\n",
    "            y_pred = torch.argmax(Y_pred, dim=-1)\n",
    "            acc = torch.sum(y == y_pred)/y.size()[0]\n",
    "            return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HIDDEN_LAYER:\n",
    "    model = ModelEmbeddingNN()\n",
    "else:\n",
    "    model = ModelEmbeddingLR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the loss and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()    # cross entropy loss\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bags_uni_val, X_bags_bi_val, X_bags_tri_val = bag_generator(X_idx_val, X_freqs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [02:47<00:00, 27.90s/it]\n"
     ]
    }
   ],
   "source": [
    "loss_train_history = []\n",
    "acc_train_history = []\n",
    "loss_val_history = []\n",
    "acc_val_history = []\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    loss_train = 0\n",
    "    acc = 0\n",
    "    cnt = 0\n",
    "    model.train()\n",
    "    n_indices = torch.randperm(len(X_idx_train)) \n",
    "    for i in range(0, len(X_idx_train), BATCH_SIZE):\n",
    "        X_idx_batch_train = [X_idx_train[idx] for idx in n_indices[i:i+BATCH_SIZE]]\n",
    "        X_freqs_batch_train = [X_freqs_train[idx] for idx in n_indices[i:i+BATCH_SIZE]]\n",
    "        X_bags_uni_train, X_bags_bi_train, X_bags_tri_train = bag_generator(X_idx_batch_train, X_freqs_batch_train)\n",
    "        y_true = y_train[n_indices[i:i+BATCH_SIZE]]\n",
    "        y_pred = model((X_bags_uni_train, X_bags_bi_train, X_bags_tri_train))\n",
    "        loss = loss_fn(y_pred, y_true)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    loss_val, acc_val = model.evaluate((X_bags_uni_val, X_bags_bi_val, X_bags_tri_val), y_val, loss_fn)\n",
    "    loss_val_history += [loss_val.item()]\n",
    "    acc_val_history += [acc_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(acc_val_history) + 1)\n",
    "plt.plot(epochs, acc_val_history, 'bo', label='Validation accuracy')\n",
    "plt.title('Validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(loss_val_history) + 1)\n",
    "plt.plot(epochs, loss_val_history, 'rx', label='Validation loss')\n",
    "plt.title('Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelEmbeddingLR(\n",
       "  (embed_uni): EmbeddingBag(2053, 32, mode=sum)\n",
       "  (embed_bi): EmbeddingBag(4099, 64, mode=sum)\n",
       "  (embed_tri): EmbeddingBag(4099, 128, mode=sum)\n",
       "  (fc_uni): Linear(in_features=32, out_features=39, bias=True)\n",
       "  (fc_bi): Linear(in_features=64, out_features=39, bias=True)\n",
       "  (fc_tri): Linear(in_features=128, out_features=39, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15, 36, 19, 18, 28, 19, 11, 14, 32,  3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_pred = torch.argmax(model((X_bags_uni_val, X_bags_bi_val, X_bags_tri_val)), dim=-1)\n",
    "y_val_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ara     0.9933    0.9959    0.9946      1479\n",
      "         ber     0.8021    0.8326    0.8171      1529\n",
      "         bul     0.9661    0.9225    0.9438      1484\n",
      "         ces     0.9685    0.9873    0.9778      1497\n",
      "         cmn     0.9986    0.9973    0.9980      1475\n",
      "         dan     0.9587    0.9847    0.9715      1507\n",
      "         deu     0.9911    0.9778    0.9844      1484\n",
      "         ell     1.0000    1.0000    1.0000      1511\n",
      "         eng     0.9814    0.9852    0.9833      1557\n",
      "         epo     0.9905    0.9805    0.9855      1590\n",
      "         fin     0.9835    0.9917    0.9876      1446\n",
      "         fra     0.9953    0.9764    0.9858      1525\n",
      "         hau     0.9879    0.9919    0.9899      1479\n",
      "         heb     1.0000    1.0000    1.0000      1480\n",
      "         hun     0.9854    0.9917    0.9885      1562\n",
      "         ina     0.9485    0.9595    0.9540      1458\n",
      "         ita     0.9738    0.9671    0.9705      1461\n",
      "         jpn     0.9987    0.9987    0.9987      1493\n",
      "         kab     0.8357    0.7950    0.8148      1561\n",
      "         lat     0.9691    0.9717    0.9704      1483\n",
      "         lfn     0.9737    0.9487    0.9610      1520\n",
      "         lit     0.9911    0.9925    0.9918      1464\n",
      "         mar     1.0000    1.0000    1.0000      1505\n",
      "         mkd     0.9179    0.9388    0.9282      1488\n",
      "         nld     0.9697    0.9846    0.9771      1494\n",
      "         pes     0.9955    0.9948    0.9952      1549\n",
      "         pol     0.9883    0.9890    0.9886      1540\n",
      "         por     0.9776    0.9731    0.9754      1525\n",
      "         ron     0.9799    0.9838    0.9819      1485\n",
      "         rus     0.9629    0.9732    0.9680      1493\n",
      "         spa     0.9529    0.9663    0.9596      1424\n",
      "         srp     0.9163    0.9272    0.9218      1512\n",
      "         swc     0.9796    0.9904    0.9850      1454\n",
      "         swe     0.9794    0.9584    0.9688      1538\n",
      "         tlh     0.9901    0.9934    0.9918      1514\n",
      "         tok     0.9967    0.9993    0.9980      1510\n",
      "         tur     0.9939    0.9898    0.9918      1470\n",
      "         ukr     0.9826    0.9658    0.9741      1519\n",
      "         vie     0.9987    0.9987    0.9987      1487\n",
      "\n",
      "    accuracy                         0.9709     58552\n",
      "   macro avg     0.9712    0.9712    0.9711     58552\n",
      "weighted avg     0.9710    0.9709    0.9709     58552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_val_pred, target_names=langs, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1473    0    0 ...    0    0    0]\n",
      " [   0 1273    0 ...    0    0    0]\n",
      " [   0    0 1369 ...    0    5    0]\n",
      " ...\n",
      " [   0    2    0 ... 1455    0    0]\n",
      " [   0    0    5 ...    0 1467    0]\n",
      " [   0    0    0 ...    0    0 1485]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text: str, MAXES):\n",
    "    hashvals = ngrams2hashvals(all_ngrams(text), MAXES)\n",
    "    hash2freqs_l = list(map(rel_freqs, hashvals))\n",
    "    bags = ngrams_bags(hash2freqs_l)\n",
    "    return bag_generator([bags[0]], [bags[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents = ['Groovin\\' on a Sunday afternoon',\n",
    "'La Folle Complainte', \n",
    "'Vent\\'anni o poco più', \n",
    "'Tous les garçons et les filles',\n",
    "'Mambo italiano']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groovin' on a Sunday afternoon -> eng\n",
      "La Folle Complainte -> fra\n",
      "Vent'anni o poco più -> ita\n",
      "Tous les garçons et les filles -> fra\n",
      "Mambo italiano -> swc\n"
     ]
    }
   ],
   "source": [
    "for sent in test_sents:\n",
    "    bags = encode(sent, MAXES)\n",
    "    print(sent, '->', idx2lang[torch.argmax(model((bags[0], bags[1], bags[2])), dim=-1).item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
